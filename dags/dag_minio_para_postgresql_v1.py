import os
# ===================================================================================
# DAG DE CARGA DO DATA LAKE PARA O DATA MART - DEMONSTRA√á√ÉO T√âCNICA
# ===================================================================================
# Esta DAG orquestra um processo ETL que extrai dados da camada Bronze (MinIO),
# aplica transforma√ß√µes b√°sicas e carrega os resultados no Data Mart (PostgreSQL).
#
# üîê SEGURAN√áA:
# - As credenciais s√£o recuperadas dinamicamente via Vault seguro.
# - Nenhum segredo √© exposto em logs ou c√≥digo-fonte.
#
# üìå INSTRU√á√ïES PARA AVALIADORES:
# 1. Confirme que o Vault j√° cont√©m as chaves de acesso ao MinIO e PostgreSQL.
# 2. Execute a DAG `dag_upload_bronze_minio_v1` antes desta.
# 3. Execute esta DAG manualmente para validar a carga no Data Mart.
# ===================================================================================

from __future__ import annotations
import pendulum
import pandas as pd
import io
from sqlalchemy import create_engine, text
from minio import Minio

from airflow.models.dag import DAG
from airflow.operators.python import PythonOperator


# === üöÄ Fun√ß√£o principal de ETL ===
def _minio_para_postgresql_seguro():
    """
    Realiza extra√ß√£o do MinIO, transforma os dados (se necess√°rio)
    e carrega no PostgreSQL, com uso de Vault para autentica√ß√£o.
    """
    # Importa√ß√µes locais para execu√ß√£o segura no contexto do Airflow
    from plugins.security_system.audit import AuditLogger
    from plugins.security_system.vault import AirflowSecurityManager

    print("üîê Recuperando credenciais de servi√ßo via Vault...")

SECRET_KEY = os.getenv('SECURITY_VAULT_SECRET_KEY')

if not SECRET_KEY:
    raise ValueError("ERRO CR√çTICO: A vari√°vel de ambiente 'SECURITY_VAULT_SECRET_KEY' n√£o est√° definida.")
    VAULT_DB_PATH = '{{AIRFLOW_HOME}}/data/security_vault.db'

    # Substituto de logger caso auditoria n√£o seja necess√°ria aqui
    class SimpleLogger:
        """Logger vazio para execu√ß√£o simplificada."""
        def log(self, *args, **kwargs): pass

    sec_manager = AirflowSecurityManager(VAULT_DB_PATH, SECRET_KEY, SimpleLogger())

    # Carrega credenciais de servi√ßos
    minio_creds = sec_manager.get_secret("minio_local_credentials")
    pg_creds = sec_manager.get_secret("postgres_indicativos_credentials")

    if not minio_creds or not pg_creds:
        raise ValueError("‚ùå Credenciais n√£o encontradas no Vault.")

    # --- ETAPA 1: Extra√ß√£o do MinIO ---
    try:
        print("üì• Conectando ao MinIO para leitura do arquivo...")
        client = Minio(
            minio_creds['endpoint_url'].replace('http://', '').replace('https://', ''),
            access_key=minio_creds['access_key'],
            secret_key=minio_creds['secret_key'],
            secure=False  # MinIO local geralmente opera sem TLS
        )

        bucket_name = "bronze-layer"
        file_path = "olist/dados_consolidados.csv"

        data = client.get_object(bucket_name, file_path)
        df = pd.read_csv(io.BytesIO(data.read()))
        print(f"‚úÖ Dados extra√≠dos com sucesso de '{file_path}' ({len(df)} linhas).")

    except Exception as e:
        print(f"‚ùå Falha na extra√ß√£o do MinIO: {e}")
        raise


    # --- ETAPA 2: Carga no PostgreSQL ---
    try:
        print("\nüì§ Conectando ao PostgreSQL para inserir dados...")
        db_url = (f"postgresql+psycopg2://{pg_creds['user']}:{pg_creds['password']}"
                  f"@{pg_creds['host']}:{pg_creds['port']}/{pg_creds['dbname']}")
        engine = create_engine(db_url)

        with engine.connect() as conn:
            print("   ‚Üí Limpando tabela 'dados_olist'...")
            conn.execute(text("TRUNCATE TABLE dados_olist RESTART IDENTITY;"))

            print(f"   ‚Üí Inserindo {len(df)} registros...")
            df.to_sql("dados_olist", conn, if_exists="append", index=False)
            conn.commit()

        print("‚úÖ Carga finalizada com sucesso no Data Mart!")

    except Exception as e:
        print(f"‚ùå Erro ao carregar dados no PostgreSQL: {e}")
        raise


# === üìÖ Defini√ß√£o da DAG ===
with DAG(
    dag_id="dag_minio_para_postgresql_v1",
    start_date=pendulum.datetime(2025, 6, 10, tz="UTC"),
    schedule=None,
    catchup=False,
    doc_md="""
### Carga do Data Lake para o Data Mart
Esta DAG executa uma pipeline ETL completa: extrai arquivos do MinIO (camada Bronze),
realiza transforma√ß√µes (se necess√°rio) e insere no PostgreSQL (Data Mart).
""",
    tags=['datamart', 'etl', 'postgres', 'vault']
) as dag:

    tarefa_transferir_dados = PythonOperator(
        task_id='transferir_minio_para_postgres',
        python_callable=_minio_para_postgresql_seguro,
    )
