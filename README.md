# Pipeline de Dados Seguro: Da Ingest√£o √† Visualiza√ß√£o Anal√≠tica

## I. üéØ Objetivo do Case

### Desafio
Implementar um pipeline de dados completo com:
- Ingest√£o de m√∫ltiplas fontes (APIs, datasets)
- Processamento distribu√≠do seguro
- Armazenamento em camadas (Data Lake Medallion)
- Visualiza√ß√£o anal√≠tica
- Garantia de seguran√ßa e qualidade em todas as etapas

### Compet√™ncias Demonstradas
1. **Orquestra√ß√£o** com Apache Airflow (DAGs modularizadas)
2. **Processamento** com Apache Spark (transforma√ß√µes distribu√≠das)
3. **Modelagem dimensional** (Star Schema no PostgreSQL)
4. **Framework de seguran√ßa customizado** (Vault criptografado + auditoria)
5. **Quality Gates** com Great Expectations
6. **Data Lake** com arquitetura Medallion (MinIO)
7. **Visualiza√ß√£o** com Streamlit e Grafana
8. **Containeriza√ß√£o** com Docker/Docker Compose

### Valor de Neg√≥cio
- Processamento seguro de dados sens√≠veis
- Gera√ß√£o de insights acion√°veis para tomada de decis√£o
- Base para solu√ß√µes escal√°veis em ambientes corporativos
- Compliance com LGPD e regulamenta√ß√µes de seguran√ßa

## II. üèõÔ∏è Arquitetura da Solu√ß√£o

### Diagrama de Arquitetura
```mermaid
graph TD
    F[Fontes] --> O[Orquestra√ß√£o]
    O --> DL[Data Lake]
    DL --> P[Processamento]
    P --> DW[Data Warehouse]
    DW --> V[Visualiza√ß√£o]
    
    subgraph F
        API[APIs Externas]
        DS[Datasets]
    end
    
    subgraph O
        AF[Airflow]
    end
    
    subgraph DL
        B[Bronze - Raw]
        S[Silver - Cleansed]
        G[Gold - Aggregated]
    end
    
    subgraph P
        SP[Spark]
        GE[Great Expectations]
    end
    
    subgraph DW
        PG[PostgreSQL]
    end
    
    subgraph V
        ST[Streamlit]
        GF[Grafana]
    end
    
    SEC[üîê Seguran√ßa] --> O
    SEC --> DL
    SEC --> P
```

### Componentes T√©cnicos
| Camada             | Tecnologias                          | Fun√ß√£o Principal                     |
|--------------------|--------------------------------------|--------------------------------------|
| **Orquestra√ß√£o**   | Apache Airflow, Docker               | Coordena√ß√£o do fluxo de dados        |
| **Seguran√ßa**      | Vault AES-128, Auditoria Customizada | Prote√ß√£o de credenciais e dados      |
| **Armazenamento**  | MinIO (S3-compatible)                | Data Lake Medallion (Bronze/Silver/Gold) |
| **Processamento**  | Apache Spark, Pandas                 | Transforma√ß√µes em larga escala       |
| **Qualidade**      | Great Expectations                   | Valida√ß√£o de dados                   |
| **Data Warehouse** | PostgreSQL                           | Modelo dimensional Star Schema       |
| **Visualiza√ß√£o**   | Streamlit, Grafana                   | Dashboards anal√≠ticos                |

## III. ‚öôÔ∏è Explica√ß√£o sobre o Case Desenvolvido

### Fluxo de Trabalho Principal
1. **Coleta Segura**: 
   - Ingest√£o de dados via APIs (Banco Central, OpenWeather) e datasets (Olist)
   - Credenciais gerenciadas pelo Security Vault
   
2. **Processamento Inicial**:
   - Consolida√ß√£o de fontes
   - Mascaramento de PII (dados sens√≠veis)
   - Persist√™ncia na camada Silver

3. **Transforma√ß√µes Avan√ßadas**:
   - Agrega√ß√µes com Spark
   - Aplica√ß√£o de regras de neg√≥cio
   - Persist√™ncia na camada Gold

4. **Garantia de Qualidade**:
   - Valida√ß√£o com Great Expectations
   - Bloqueio de dados inv√°lidos

5. **Carga no Data Mart**:
   - Popula√ß√£o do modelo Star Schema
   - Otimiza√ß√£o para consultas anal√≠ticas

6. **Visualiza√ß√£o**:
   - Dashboards interativos com Streamlit
   - Monitoramento operacional com Grafana

### Diferenciais T√©cnicos
- **Security Framework Customizado**:
  - Criptografia AES-128 para credenciais
  - Sistema de auditoria com rastreabilidade completa
  - Rota√ß√£o autom√°tica de chaves
- **Arquitetura Medallion**:
  - Camadas Bronze (raw), Silver (cleansed), Gold (enriched)
  - Lifecycle management autom√°tico
- **Fail-Fast Strategy**:
  - Valida√ß√µes em pontos cr√≠ticos do pipeline
  - Interrup√ß√£o imediata em falhas de qualidade

## IV. üß† Melhorias e Considera√ß√µes Finais

### Decis√µes de Projeto
1. **Separa√ß√£o de Responsabilidades**:
   - Vault Manager (gest√£o de segredos) isolado do Security Manager (UI)
   
2. **Automa√ß√£o de Refatora√ß√£o**:
   - Scripts Python para adapta√ß√£o autom√°tica de caminhos
   
3. **Gest√£o de Credenciais**:
   - .env para desenvolvimento ‚Üí Servi√ßos de segredos em produ√ß√£o

### Melhorias Propostas
1. **Infraestrutura como C√≥digo**:
   - Terraform para provisionamento em nuvem
   - Ansible para configura√ß√£o de servidores
   
2. **CI/CD Pipeline**:
   - GitHub Actions para testes automatizados
   - Deploy cont√≠nuo de DAGs
   
3. **Observabilidade**:
   - Prometheus + Grafana para monitoramento
   - Jaeger para distributed tracing
   
4. **Cat√°logo de Dados**:
   - Apache Atlas para metadata management
   - Linhagem de dados completa

### Considera√ß√µes Finais
- Arquitetura validada para ambientes de produ√ß√£o
- Foco em seguran√ßa, governan√ßa e compliance
- Base s√≥lida para escalabilidade em nuvem
- Documenta√ß√£o completa para manuten√ß√£o

## V. üõ†Ô∏è Reprodutibilidade da Arquitetura

### Pr√©-requisitos
- Docker 20.10+
- Docker Compose 2.20+
- Python 3.8+
- 8GB RAM (recomendado 16GB)

### Instala√ß√£o e Execu√ß√£o
```bash
# 1. Clonar reposit√≥rio
git clone https://github.com/felipesbonatti/case-data-master-engenharia-de-dados
cd case-data-engineering

# 2. Configurar ambiente
cp .env.example .env
nano .env  # Preencher com suas credenciais

# 3. Iniciar containers
docker-compose up -d --build

# 4. Popular security vault
docker-compose exec airflow-scheduler python /opt/airflow/scripts/setup_vault_secrets.py

# 5. Acessar servi√ßos:
# Airflow: http://localhost:8080 (admin/admin)
# MinIO: http://localhost:9001 (minioadmin/minio_secure_2024)
# Streamlit: http://localhost:8501
```

### Estrutura de Diret√≥rios
```
case-data-engineering/
‚îú‚îÄ‚îÄ dags/               # Fluxos do Airflow
‚îú‚îÄ‚îÄ plugins/            # Framework de seguran√ßa
‚îú‚îÄ‚îÄ scripts/            # Utilit√°rios de configura√ß√£o
‚îú‚îÄ‚îÄ data/               # Datasets de exemplo
‚îú‚îÄ‚îÄ dashboard/          # App Streamlit
‚îú‚îÄ‚îÄ docker-compose.yml  # Defini√ß√£o de servi√ßos
‚îî‚îÄ‚îÄ requirements.txt    # Depend√™ncias Python
```

### Valida√ß√£o da Instala√ß√£o
```bash
# Executar health check
docker-compose exec airflow-scheduler python /opt/airflow/scripts/health_check.py

# Sa√≠da esperada:
# ‚úÖ PostgreSQL: Connected
# ‚úÖ MinIO: Connected
# ‚úÖ Security Vault: Initialized
```

### Solu√ß√£o de Problemas Comuns
| Problema               | Solu√ß√£o                          |
|------------------------|----------------------------------|
| Portas conflitantes    | Alterar portas no .env           |
| DAGs n√£o aparecem      | Verificar logs do scheduler      |
| Erros de conex√£o       | Validar credenciais no vault     |
| Falta de recursos      | Aumentar mem√≥ria do Docker       |
```

