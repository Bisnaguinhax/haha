#!/usr/bin/env python3
# ================================================================================
# CONVERS√ÉO PARA AVRO - Escrita
# ================================================================================
# Este script converte um CSV local contendo dados do IPCA para o formato Avro,
# demonstrando como persistir dados em formatos otimizados para Data Lake.
# ================================================================================

import fastavro
import pandas as pd
import os
import sys

caminho_base = "{{AIRFLOW_HOME}}/data/indicadores"
caminho_csv = os.path.join(caminho_base, "ipca_coletado.csv")
caminho_avro = os.path.join(caminho_base, "ipca.avro")

print(f"üìÑ Lendo CSV de: {caminho_csv}")
if not os.path.exists(caminho_csv):
    print("‚ùå Arquivo CSV n√£o encontrado. Verifique a execu√ß√£o da DAG de coleta primeiro.")
    sys.exit(1)

df_ipca = pd.read_csv(caminho_csv)

# Defini√ß√£o de schema exigida pelo Avro
schema = {
    "type": "record",
    "name": "IPCA",
    "fields": [
        {"name": "data", "type": "string"},
        {"name": "valor", "type": "string"}  # Tipo string para garantir compatibilidade
    ]
}

print("üõ†Ô∏è  Convertendo registros para Avro...")
records = df_ipca.to_dict("records")
with open(caminho_avro, "wb") as avro_file:
    fastavro.writer(avro_file, schema, records)

print(f"‚úÖ Convers√£o conclu√≠da. Arquivo salvo em: {caminho_avro}")
